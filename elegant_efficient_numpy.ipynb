{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elegant and efficient NumPy\n",
    "\n",
    "This tutorial is for those who have clobbered together an analysis script or two, using basic Python and NumPy, and want to learn how to write more elegant and efficient analysis code. We will dive into how NumPy works behind the scenes and use this knowledge to our advantage. This tutorial also serves as an introduction to reading the definitive work on this topic: [Guide to NumPy](http://web.mit.edu/dvp/Public/numpybook.pdf) by Travis E. Oliphant, the initial creator of NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why can NumPy be so fast?\n",
    "Python, being an interpreted programming language, is quite slow. Manipulating large amounts of numbers using Python's build-in lists would be impractically slow for any serious data analysis. Yet, the `numpy` package can be really fast. What gives?\n",
    "\n",
    "How fast can NumPy be? Let's try summing together 100000000 random numbers in a fast language, C, and using NumPy. First, the C version that uses a naive approach of doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile random.c\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#define N_ELEMENTS 100000000\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    double* a = (double*) malloc(sizeof(double) * N_ELEMENTS);\n",
    "    \n",
    "    int i;\n",
    "    for(i=0; i<N_ELEMENTS; ++i) {\n",
    "        a[i] = (double) rand() / RAND_MAX;\n",
    "    }\n",
    "    \n",
    "    double sum = 0;\n",
    "    for(i=0; i<N_ELEMENTS; ++i) {\n",
    "        sum += a[i];\n",
    "    }\n",
    "\n",
    "    printf(\"%f\", sum);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above snippet of C code creates an array of 100000000 64-bit floating point numbers, chosen randomly between 0 and 1, adds them all together, and displays the result.\n",
    "\n",
    "The cell below will compile the above code using the default C compiler, using maximum optimization settings.\n",
    "On Linux and OSX systems, a compiler should be readily available.\n",
    "If you are running this in the cloud (e.g. [mybinder.org](https://mybinder.org)), you're also good to go.\n",
    "On Windows, you may need to install a C compiler and modify the code below to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc random.c -o random -Ofast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the program compiled and ready to run, let's see how long it takes. Here, I'm using the `%%timeit` magic cell function to instruct the Jupyter Notebook to run the program 10 times and report the average running time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "!random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beating C-code with NumPy\n",
    "<img src=\"images/race.jpg\" style=\"float: right; width: 300px; margin: 10px; margin-top: -10px\"/>\n",
    "On my laptop, the C version took Â±1.33 s to run. How long did it take on the machine you are currently using?\n",
    "\n",
    "As a test of your current knowledge of NumPy, can you write a little snippet of Python + NumPy code that performs the same operations, but faster than the naive C program above? To recap, your program should:\n",
    "\n",
    " 1. Create an array of 100000000 random values, each value between 0 and 1.\n",
    " 2. Compute and print the sum of the array. It's ok if you get a different result than the C code. They are random numbers after all.\n",
    " \n",
    "We can use the `%%timeit` magic again to determine the running time of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "# Write your Python + NumPy code here and execute the cell to see how long it takes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were unable to beat the naive C code, please review the [NumPy basics](https://docs.scipy.org/doc/numpy/user/quickstart.html).\n",
    "\n",
    "How did we beat the C version?\n",
    "The NumPy module is written in C, so it must be doing something more clever than the naive C code above.\n",
    "The truth is that behind the scenes, NumPy is using non-naive, highly optimized, C and FORTRAN code.\n",
    "\n",
    "## The man behind the curtain: Basic Linear Algebra Subprograms\n",
    "<img src=\"images/wizard-of-oz.jpg\" style=\"float: right; width: 300px; margin: 10px; margin-top: -10px\"/>\n",
    "\n",
    "[Basic Linear Algebra Subprograms (BLAS)](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) for Fortran was published in 1979 [1] and is a collection algorithms for common mathematical operations that are performed on arrays of numbers.\n",
    "Algorithms such as element-wise sum, matrix multiplication, computing the vector length, etc.\n",
    "\n",
    "The API of that software library was later standardized, and today there are many modern implementations available. These libraries represent over 40 years of optimizing efforts and make use of [specialized CPU instructions for manipulating arrays](https://www.youtube.com/watch?v=Pc8DfEyAxzg&list=PLzLzYGEbdY5lrUYSssHfk5ahwZERojgid).\n",
    "In other words, they are *fast*.\n",
    "\n",
    "[1] C. L. Lawson, R. J. Hanson, D. R. Kincaid, and F. T. Krogh. 1979. Basic Linear Algebra Subprograms for Fortran Usage. ACM Trans. Math. Softw. 5, 3 (September 1979), 308-323. DOI: https://doi.org/10.1145/355841.355847 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we should strive to push as much of the work as possible into NumPy's heavily optimized innards.\n",
    "Less code for us to write and better performance to boot.\n",
    "However, this does mean we will have to get intimately familiar with its [API](https://docs.scipy.org/doc/numpy/reference/).\n",
    "\n",
    "<img src=\"images/vector.png\" style=\"float: right; margin: 10px, margin-top: -10px; width: 300px\"/>\n",
    "\n",
    "### Leverage the power of BLAS\n",
    "\n",
    "Let's see another example of how using BLAS will beat naive code in both performance and lines of code.\n",
    "One of the functions inside the BLAS library is a function to compute the \"norm\" of a vector, which is the same as computing its length, using the [Pythagorean theorem](https://en.wikipedia.org/wiki/Pythagorean_theorem):\n",
    "$\\sqrt(a[0]^2 + a[1]^2 + \\ldots)$.\n",
    "NumPy exposes this function for us as [`np.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html).\n",
    "\n",
    "In the cell below, I've mocked up a naive \"manual\" version of computing the vector norm.\n",
    "It begins by creating a random vector with 100000000 dimensions and proceeds by using the Pythagorean theorem to compute its norm/length.\n",
    "The cell is again decorated with the magic `%%timeit` function to measure how long it takes to execute.\n",
    "Run it and take note of how long this naive version takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "a = np.random.rand(100000000)\n",
    "l = np.sqrt(np.sum(a ** 2))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ask you again to beat the above time.\n",
    "In the cell below, use the [`np.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) function to do the computation.\n",
    "I've already copied the code to create the random vector and the `%%timeit` magic for you.\n",
    "Complete the code and run it to see if your version can beat my naive code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "a = np.random.rand(100000000)\n",
    "\n",
    "# Write the code to compute the vector norm/length using only one function call, here:\n",
    "# l = ...\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tutorials, we will tour some more of NumPy's nooks and crannies that are not necessarily covered in basic tutorials, but are nontheless worthwhile to know about if you are serious about learning data analysis with Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
