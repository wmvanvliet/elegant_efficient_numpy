{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strides: Why are some things fast, and other things slow?\n",
    "\n",
    "For small data sets (< 1MB), modern computers are so amazingly fast that efficiency is hardly worth thinking about.\n",
    "But if you are using NumPy, it is not uncommon to have bigger data sets that actually take some time to process, even on speedy machines.\n",
    "For example, in the previous section, we allocated data arrays of 800MB and it took a couple of seconds to process it.\n",
    "With that kind of data, speed starts to matter.\n",
    "\n",
    "Understanding the kind of operations that are expensive (take a long time) and which ones are cheap can be surprisingly hard when it comes to NumPy.\n",
    "A big part of data processing speed is memory management.\n",
    "Copying big arrays takes time, so the less of that we do, the faster our code runs.\n",
    "The rules of when NumPy copies data are not trivial and it is worth your while to take a closer look at them.\n",
    "This involves developing an understanding of how NumPy's `ndarray` datastructure works behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example: matrix transpose\n",
    "\n",
    "Transposing a matrix means that all rows become columns and all columns become rows. All off-diagonal values change places. Obviously, all this moving data around should take come time, right? Let's see how long NumPy's transpose function takes, by transposing a huge (10 000 ✕ 20 000) matrix. This time, let's exclude the time it takes to allocate this beast of a matrix and focus solely on the [np.transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "a = np.random.rand(10_000, 20_000)\n",
    "print('Matrix `a` takes up %d MB' % (a.nbytes / 10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1000\n",
    "b = a.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/magic.jpg\" style=\"width: 200px; float: right; margin: 10px; margin-top: -10px\"/>\n",
    "\n",
    "On my laptop, it takes mere nanoseconds to transpose 1600 MB of data.\n",
    "NumPy somehow avoided copying the data.\n",
    "The transpose operation is computationally so cheap that is also available through the `.T` property (it is conventially not done to expose methods that are potentially computationally expensive as properties).\n",
    "\n",
    "What black magic is going on here?\n",
    "To answer that, we must dive a little into the innards of NumPy `ndarray` datastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `ndarray` exposed\n",
    "\n",
    "The first thing you need to know about `ndarray` is that the memory backing up the `ndarray` is always a flat 1D array.\n",
    "That is how the operating system exposes memory. (This is a lie by the way, the actual memory is a fragmented mess, but the operating system shelters us from this cold harsh truth.)\n",
    "For example, a 2D matrix is stored with all the rows concatenated as a single long vector.\n",
    "\n",
    "<img src=\"images/memory_layout.png\" width=\"700\">\n",
    "\n",
    "NumPy is faking the second dimension behind the scenes!\n",
    "When we request the element at say, `[2, 3]`, NumPy converts this to the correct index in the long 1D array `[11]`.\n",
    "Converting `[2, 3]` into `[11]` is called \"raveling\", and the reverse \"unraveling\".\n",
    "\n",
    "The implications of this are many, so take let's take some time to understand it properly by writing our own `ravel()` function that converts a row and column index to the appropriate index in the 1D array.\n",
    "Use the image above as a guide. We'll discuss the answer below, but do youself a favor and don't peek before you've written the function correctly yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel(row_index, col_index, n_rows, n_cols):\n",
    "    \"\"\"Ravel a row/col matrix index to a flat vector index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row_index : int\n",
    "        The row of the requested element in the matrix.\n",
    "    col_index : int\n",
    "        The column of the requested element in the matrix.\n",
    "    n_rows : int\n",
    "        The total number of rows in the matrix.\n",
    "    n_cols : int\n",
    "        The total number of columns in the matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    index : int\n",
    "        The corresponding index in a flat 1D array.\n",
    "    \"\"\"\n",
    "    return  # Do the computation here\n",
    "\n",
    "# If you wrote the function correctly, these tests should all pass\n",
    "assert ravel(2, 3, n_rows=4, n_cols=4) == 11\n",
    "assert ravel(2, 3, n_rows=4, n_cols=8) == 19\n",
    "assert ravel(0, 0, n_rows=1, n_cols=1) == 0\n",
    "assert ravel(3, 3, n_rows=4, n_cols=4) == 15\n",
    "assert ravel(3_465, 18_923, n_rows=10_000, n_cols=20_000) == 69_318_923"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope that, after a bit of trial and error, you managed to get this right.\n",
    "To get to the next row, we have to skip over `n_cols` indices.\n",
    "To get to the next column, we can just add `1`.\n",
    "What would it take to generalize this code to work with an arbitrary number of dimensions?\n",
    "\n",
    "NumPy solves this through the concept of \"strides\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((4, 8))  # Create a 4 x 8 matrix\n",
    "a.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above tells us that to get to the next row in this matrix, we have to skip ahead 64 bytes.\n",
    "64? Yes!\n",
    "We have created a matrix consisting of double-precision floating point numbers.\n",
    "Each one of those bad boys takes up 8 bytes, so all the indices are multiplied by 8 to get to the proper byte in the memory array.\n",
    "To move to the next column in the matrix, we skip ahead 8 bytes.\n",
    "\n",
    "What about a 5D `ndarray`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((4, 5, 6, 7, 8))\n",
    "a.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.strides` attribute contains for each dimension, the number of bytes we have to skip over to get to the next element along that dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The mystery of `transpose()` revealed\n",
    "\n",
    "So how does NumPy manage to implement `transpose()` so efficiently?\n",
    "Look what happens to the `.strides`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10_000, 20_000)\n",
    "print(f'Normal: {a.shape=} {a.strides=}')\n",
    "a = a.T\n",
    "print(f'Transposed: {a.shape=} {a.strides=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just flipped the `.strides`!\n",
    "The huge 1D array containing the data is untouched.\n",
    "Normally, a (20 000 ✕ 10 000) matrix would have strides `(80_000, 8)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(20_000, 10_000)\n",
    "b.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, our transposed `a.T` matrix has strides `(8, 160_000)`, so it did't have to move any data around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little known feature of NumPy is the `stride_tricks` module that allows you to modify the `.strides` attribute directly.\n",
    "Playing around with this is very educational:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def transpose(a):\n",
    "    \"\"\"My own transpose function\"\"\"\n",
    "    # We just flip the .strides!\n",
    "    return as_strided(a, shape=a.shape[::-1], strides=a.strides[::-1])\n",
    "\n",
    "# Test the function on a small matrix\n",
    "a = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "print('Before transpose:')\n",
    "print(a)\n",
    "print('After transpose:')\n",
    "print(transpose(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surely, `reshape` is fast\n",
    "\n",
    "Knowing about `.strides`, it should not be a surprise that changing the shape of an array through `reshape()` can be accomplished without any copying of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(20_000, 10_000)\n",
    "print(f'{a.strides=}')\n",
    "b = a.reshape(40_000, 5_000)\n",
    "print(f'{b.strides=}')\n",
    "c = a.reshape(20_000, 5_000, 2)\n",
    "print(f'{c.strides=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun and giggles, I challenge you to use `as_strided` to create a (5 ✕ 100 000 000 000) array containing on the first row all `1`'s, the second row all `2`'s, etc:\n",
    "\n",
    "```\n",
    "array([[1., 1., 1., ..., 1., 1., 1.],\n",
    "       [2., 2., 2., ..., 2., 2., 2.],\n",
    "       [3., 3., 3., ..., 3., 3., 3.],\n",
    "       [4., 4., 4., ..., 4., 4., 4.],\n",
    "       [5., 5., 5., ..., 5., 5., 5.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1., 2., 3., 4., 5.])\n",
    "a = as_strided(a, shape=..., strides=...)  # Fill in the correct shape and strides\n",
    "\n",
    "# If you got it right, these tests should pass\n",
    "assert a.shape == (5, 100_000_000_000)\n",
    "assert a[0, 23890493] == 1.\n",
    "assert a[3, 19302839] == 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fast thing + a fast thing = a fast thing?\n",
    "\n",
    "If `transpose()` is fast, and `reshape()` is fast, then doing them both must be fast too, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10_000, 20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "a.T.reshape(40_000, 5_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong! In this case, the data actually had to be copied and it's super slow (it takes *seconds* instead of nanoseconds).\n",
    "Why?\n",
    "When an `ndarray` is first created, it is laid out in memory row-by-row (see image above).\n",
    "This is also how the programming language C does it, so this is called `C_CONTIGUOUS`.\n",
    "The transpose left the data laid out in memory column-by-column.\n",
    "This is also how the programming language Fortran does it, so this is called `F_CONTIGUOUS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.flags['C_CONTIGUOUS'], a.flags['F_CONTIGUOUS'])\n",
    "print(a.T.flags['C_CONTIGUOUS'], a.T.flags['F_CONTIGUOUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why the copying of data was inevitable, look at what happens to this smaller (2 ✕ 3) matrix after transposition and reshaping. You van verify for yourself there is no way to get the final array based on the first array and some clever setting of the `.strides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print('Original array:')\n",
    "print(a)\n",
    "\n",
    "print('\\nTransposed:')\n",
    "print(a.T)\n",
    "\n",
    "print('\\nTransposed and then reshaped:')\n",
    "print(a.T.reshape(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px solid #aaccff; margin: 10px 100px; padding: 10px\">\n",
    "    <b>Main takeaway of this chapter</b>\n",
    "\n",
    "NumPy will avoid copying memory whenever it can. Whether it can depends on what kind of layout the data is currently in.\n",
    "</div>\n",
    "\n",
    "In the following chapter, we will look at another way NumPy avoids copying data, namely through \"views\".\n",
    "\n",
    "<a href=\"views.ipynb\" style=\"font-size: 20px;\">Continue to next chapter</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
