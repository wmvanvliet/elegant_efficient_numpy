{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAST: How can NumPy be so fast?\n",
    "<img src=\"images/race.jpg\" style=\"float: right; width: 300px; margin: 10px; margin-top: -10px\"/>\n",
    "\n",
    "Python, being an interpreted programming language, is quite slow. Manipulating large amounts of numbers using Python's build-in lists would be impractically slow for any serious data analysis. Yet, the `numpy` package can be really fast. What gives?\n",
    "\n",
    "How fast can NumPy be? Let's race NumPy against C. The contest will be to sum together 100 000 000 random numbers. I will write the C version, you get to write the NumPy version.\n",
    "\n",
    "Below is my, admittedly naive, C version. Running this code cell will write the code to `random.c` on your local system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile random.c\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#define N_ELEMENTS 100000000\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    double* a = (double*) malloc(sizeof(double) * N_ELEMENTS);\n",
    "    \n",
    "    int i;\n",
    "    for(i=0; i<N_ELEMENTS; ++i) {\n",
    "        a[i] = (double) rand() / RAND_MAX;\n",
    "    }\n",
    "    \n",
    "    double sum = 0;\n",
    "    for(i=0; i<N_ELEMENTS; ++i) {\n",
    "        sum += a[i];\n",
    "    }\n",
    "\n",
    "    printf(\"%f\", sum);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above snippet of C code creates an array of 100 000 000 64-bit floating point numbers, chosen randomly between 0 and 1, adds them all together, and displays the result.\n",
    "\n",
    "The cell below will compile the above code using the default C compiler, using maximum optimization settings.\n",
    "On Linux and OSX systems, a compiler should be readily available.\n",
    "If you are running this in the cloud (e.g. [mybinder.org](https://mybinder.org)), you're also good to go.\n",
    "On Windows, you may need to install a C compiler and modify the code below to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc random.c -o random -Ofast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the program compiled and ready to run, let's see how long it takes. Here, I'm using the `%%timeit` magic cell function to instruct the Jupyter Notebook to run the program 10 times and report the average running time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "import subprocess\n",
    "result = subprocess.check_output('./random')\n",
    "print(result.decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beating C-code with NumPy\n",
    "\n",
    "On my laptop, the C version took ±1.33 s to run.\n",
    "Of course, there is a little overhead to calling an external program, but the running time will be dominated by the big summation loop.\n",
    "How long did it take on the machine you are currently using?\n",
    "\n",
    "As a test of your current knowledge of NumPy, I now ask you to write a little snippet of Python + NumPy code that performs the same operations, but faster than the naive C program above. To recap, your program should:\n",
    "\n",
    " 1. Create an array of 100 000 000 random values, each value between 0 and 1.\n",
    " 2. Compute and print the sum of the array. It's ok if you get a different result than the C code. They are random numbers after all.\n",
    " \n",
    "We can use the `%%timeit` magic again to determine the running time of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "# Write your Python + NumPy code here and execute the cell to see how long it takes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were unable to beat the naive C code, please review the [NumPy basics](https://docs.scipy.org/doc/numpy/user/quickstart.html).\n",
    "\n",
    "How did NumPy beat the C version?\n",
    "The NumPy module is written in C, so it must be doing something more clever than the naive C code above.\n",
    "For one, it is using a faster random number generation algorithm than I did in the C code (thanks to Lasse Kärkkäinen for [pointing this out](https://github.com/wmvanvliet/elegant_efficient_numpy/issues/1)).\n",
    "What's more, NumPy is using non-naive, highly optimized, C and FORTRAN code, designed to squeeze the most out of your CPU when it comes to manipulating data arrays.\n",
    "\n",
    "## The man behind the curtain: Basic Linear Algebra Subprograms\n",
    "<img src=\"images/wizard-of-oz.jpg\" width=\"300\" style=\"float: right; width: 300px; margin: 10px;\"/>\n",
    "\n",
    "[Basic Linear Algebra Subprograms (BLAS)](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) for Fortran was published in 1979 [1] and is a collection of algorithms for common mathematical operations that are performed on arrays of numbers.\n",
    "Algorithms such as element-wise sum, matrix multiplication, computing the vector length, etc.\n",
    "\n",
    "The API of that software library was later standardized, and today there are many modern implementations available. These libraries represent over 40 years of optimizing efforts and make use of [specialized CPU instructions for manipulating arrays](https://www.youtube.com/watch?v=Pc8DfEyAxzg&list=PLzLzYGEbdY5lrUYSssHfk5ahwZERojgid).\n",
    "In other words, they are *fast*.\n",
    "\n",
    "[1] C. L. Lawson, R. J. Hanson, D. R. Kincaid, and F. T. Krogh. 1979. Basic Linear Algebra Subprograms for Fortran Usage. ACM Trans. Math. Softw. 5, 3 (September 1979), 308-323. DOI: https://doi.org/10.1145/355841.355847 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proper installation of NumPy will outsource most of the heavy lifting to a modern BLAS library.\n",
    "Hence, we should strive to push as much of the work as possible into NumPy's heavily optimized innards.\n",
    "Less code for us to write and better performance to boot.\n",
    "However, this does mean we will have to get intimately familiar with its [API](https://docs.scipy.org/doc/numpy/reference/).\n",
    "\n",
    "\n",
    "### Leverage the power of BLAS\n",
    "<img src=\"images/vector.png\" width=\"200\" style=\"float: right; margin: 10px; width: 200px\"/>\n",
    "\n",
    "Let's see another example of how using BLAS will beat naive code in both performance and amount of code.\n",
    "One of the functions inside the BLAS library is a function to compute the \"norm\" of a vector, which is the same as computing its length, using the [Pythagorean theorem](https://en.wikipedia.org/wiki/Pythagorean_theorem):\n",
    "$\\sqrt(a[0]^2 + a[1]^2 + \\ldots)$.\n",
    "NumPy exposes this function for us as [`np.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html).\n",
    "\n",
    "In the cell below, I've mocked up a naive \"manual\" version of computing the vector norm.\n",
    "It begins by creating a random vector with 100 000 000 dimensions and proceeds by using the Pythagorean theorem to compute its norm/length.\n",
    "The cell is again decorated with the magic `%%timeit` function to measure how long it takes to execute.\n",
    "Run it and take note of how long this \"manual\" version takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=0)\n",
    "a = rng.random(100_000_000)\n",
    "l = np.sqrt(np.sum(a ** 2))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ask you again to beat the above time.\n",
    "In the cell below, use the [`np.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) function to do the computation.\n",
    "I've already copied the code to create the random vector and the `%%timeit` magic for you.\n",
    "Complete the code and run it to see if your version can beat my naive code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 1\n",
    "\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=0)\n",
    "a = rng.random(100_000_000)\n",
    "\n",
    "# Write the code to compute the vector norm/length using only one function call, here:\n",
    "# l = ...\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px solid #aaccff; margin: 10px 100px; padding: 10px\">\n",
    "    <b>Main takeaway of this chapter</b>\n",
    "    \n",
    "The best way to make your analysis code more elegant and efficient is to learn more about the <a href=\"https://docs.scipy.org/doc/numpy/reference/\">NumPy API</a>).\n",
    "</div>\n",
    "\n",
    "In the following chapters, we will tour some more of NumPy's nooks and crannies that are not necessarily covered in basic tutorials, but are nontheless worthwhile to know about if you are serious about learning data analysis with Python.\n",
    "\n",
    "<a href=\"fast_vs_slow.ipynb\" style=\"font-size: 20px;\">Continue to next chapter</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
